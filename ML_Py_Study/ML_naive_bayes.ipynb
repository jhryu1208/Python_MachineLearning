{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### <u>나이브 베이즈(naive bayes) 분류기</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`나이브 베이즈(naive bayes)` 분류기는 `선형 모델`과 매우 유사하다.<br>\n",
    "`LogisticRegression`이나 `LinearSVC` 같은 선형 분류기 보다 훈련 속도가 빠르지만,<br>\n",
    "<u>일반화 성능이 조금 뒤쳐진다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`나이브베이즈(naive bayes)`</b>\n",
    "- 각 특성을 개별로 취급해 파라미터를 학습하고 그 특성에서 클래스별 통계를 단순하게 취합시킨다.\n",
    "\n",
    "<br>\n",
    "\n",
    "- `scikit-learn`에 구현된 해당 분류기는 `GaussianNB`, `BernoulliNB`, `MultinomialNB` 이렇게 3 가지이다.\n",
    "    - `GaussianNB` : 연속적인 어떤 데이터에도 적용가능\n",
    "    - `BernoulliNB` : 이진 데이터에 적용가능\n",
    "    - `MultinomialNB` : 카운트 데이터(ex 문장에 나타난 단어의 횟수)에 적용가능\n",
    "\n",
    "<br>\n",
    "\n",
    "- `BernoulliNB`와 `MultinomialNB`는 대부분 텍스트 데이터를 분류할 때 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### <u>BernoulliNB</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>각 클래스의 특성 중 0이 아닌 것이 몇 개인지 센다.</u><br>\n",
    "다음 예시를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 1, 0, 1],\n",
    "              [1, 0, 1, 1],\n",
    "              [0, 0, 0, 1],\n",
    "              [1, 0, 1, 0]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이진(binary) 특성을 4개 가진 데이터 포인트가 4개 있다.<br>\n",
    "클래스는 0과 1, 두개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력 `y`의 클래스가 `0`인 경우,<br>\n",
    "첫 번째 특성은 `0`이 두 번이고, 두 번째 특성은 `0`이 한 번 / `1`이 한 번이다.<br>\n",
    "같은 방식으로 두 번째 클래스에 해당하는 데이터 포인트에 대해서도 계산한다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 별로 `0`이 아닌 원소를 세는 과정을 요약하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 카운트:\n",
      "{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # 클래스마다 반복\n",
    "    # 특성마다 1이 나타난 횟수를 센다.\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"특성 카운트:\\n{}\".format(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### <u>MultinomialNB, GaussianNB</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 두 나이브 베이즈 모델 `MultinomialNB`와 `GaussianNB`는 계산하는 통계 데이터의 종류가 조금 다르다.<br> \n",
    "- `MultinomialNB` : 클래스별로 특성의 평균을 계산\n",
    "- `GaussianNB` : 클래스별로 각 특성의 표준편차와 평균을 저장\n",
    "\n",
    "<br>\n",
    "\n",
    "예측할 땐 데이터 포인트를 클래스의 통계 값과 비교해서 가장 잘 맞는 클래스를 예측값으로 합니다. <br>\n",
    "`MultinomialNB`와 `BernoulliNB`의 예측 공식은 `선형 모델`과 형태가 같습니다.<br>\n",
    "그러나 `나이브 베이즈` 모델의 `coef_`는 기울기 `w`가 아니라서 <u>선형 모델과는 의미가 다릅니다</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### <u>장단점과 매개변수</u>\n",
    "\n",
    "\n",
    "`MultinomialNB`와 `BernoulliNB`는 모델의 복잡도를 조절하는 `alpha` 매개변수 하나를 가지고 있습니다.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "`alpha`가 주어지면<br> 알고리즘이 모든 특성에 양의 값을 가진<br>\n",
    "가상의 데이터 포인트를 `alpha` 개수만큼 추가한다.<br>\n",
    "이는 <u>통계 데이터를 완만</u>하게 해준다.<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "`alpha`가 크면 더 완만해지고 모델의 복잡도는 낮아진다. <br>\n",
    "alpha에 따른 알고리즘 성능 변동은 비교적 크지 않아서, alpha 값이 성능 향상에 크게 기여하지 않는다.<br> \n",
    "그러나 이 값을 조정하면 어느 정도는 정확도를 높일 수 있다..<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "`GaussianNB`는 대부분 <u>매우 고차원인 데이터셋</u>에 사용하고,<br> \n",
    "`MultinomialNB`와 `BernoulliNB` 모델은 <u>텍스트 같은 희소한 데이터를 카운트</u>하는 데 사용한다.<br>\n",
    "`MultinomialNB`는 보통 <u>0이 아닌 특성이 비교적 많은 데이터셋(예를 들어 큰 문서들)</u>에서 `BernoulliNB`보다 성능이 높다.\n",
    "\n",
    "<br>\n",
    "\n",
    "`나이브 베이즈` 모델과 `선형` 모델의 장단점은 비슷하다.\n",
    "- 훈련과 예측 속도가 빠르며 훈련 과정을 이해하기 쉽다. \n",
    "- 희소한 고차원 데이터에서 잘 작동하며 비교적 매개변수에 민감하지 않다. \n",
    "- 선형 모델로는 학습 시간이 너무 오래 걸리는 매우 큰 데이터셋에는<br> 나이브 베이즈 모델을 시도해볼 만하며 종종 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "- 안드레아스 뮐러, 세라 가이도, 『파이썬 라이브러리를 활용한 머신러닝』, 박해선, 한빛미디어(2017)\n",
    "- https://tensorflow.blog/%ed%8c%8c%ec%9d%b4%ec%8d%ac-%eb%a8%b8%ec%8b%a0%eb%9f%ac%eb%8b%9d/2-3-3-%ec%84%a0%ed%98%95-%eb%aa%a8%eb%8d%b8/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
